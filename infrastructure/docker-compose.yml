---
services:
  zookeeper:
    image: docker.io/zookeeper:3.5.9
    hostname: zookeeper
    restart: on-failure
    healthcheck:
      test: zkCli.sh get / || exit 1
      interval: 1s
      retries: 15
    volumes:
      - type: volume
        source: zookeeper_data
        target: /data
      - type: volume
        source: zookeeper_datalog
        target: /datalog
      - type: volume
        source: zookeeper_logs
        target: /logs
  zookeeper_init:
    depends_on:
      - zookeeper
    image: ${ZOOKEEPER_IMAGE:-docker.io/zookeeper}:${ZOOKEEPER_VERSION:-3.5.9}
    restart: on-failure
    command:
      - bash
      - -c
      - > 
        zkCli.sh -server zookeeper:2181 get /clickhouse
        || zkCli.sh -server zookeeper:2181 create /clickhouse
    volumes:
      - type: tmpfs
        target: /data
      - type: tmpfs
        target: /datalog
      - type: tmpfs
        target: /logs
  clickhouse:
    depends_on:
      - zookeeper_init
    image: docker.io/library/clickhouse:25.4
    hostname: clickhouse
    user: root
    environment:
      CLICKHOUSE_PASSWORD: "default"
      CLICKHOUSE_UID: 0
      CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT: 1
    healthcheck:
      test: wget -O /dev/null --no-verbose --tries=1 http://127.0.0.1:8123/ping || exit 1
      interval: 1s
      retries: 15
    ports:
      - "8123:8123"
      - "9000:9000"
    volumes:
      - type: volume
        source: clickhouse_data
        target: /var/lib/clickhouse
      - type: bind
        source: ./clickhouse/users.d
        target: /etc/clickhouse-server/users.d
      - type: bind
        source: ./clickhouse/config.d
        target: /etc/clickhouse-server/config.d
      - type: bind
        source: ./clickhouse/user_scripts
        target: /var/lib/clickhouse/user_scripts
      - type: bind
        source: ./clickhouse/eudf
        target: /etc/clickhouse-server/eudf
      - type: bind
        source: ./clickhouse/user_files
        target: /var/lib/clickhouse/user_files
      - type: bind
        source: ./clickhouse-backup
        target: /etc/clickhouse-backup
      - type: bind
        source: /opt/works
        target: /opt/works
  clickhouse_replica:
    depends_on:
      - zookeeper_init
    image: docker.io/library/clickhouse:25.4
    hostname: clickhouse-replica
    user: root
    environment:
      CLICKHOUSE_PASSWORD: "default"
      CLICKHOUSE_UID: 0
    healthcheck:
      test: wget -O /dev/null --no-verbose --tries=1 http://127.0.0.1:8123/ping || exit 1
      interval: 1s
      retries: 15
    ports:
      - "8124:8123"
    volumes:
      - type: volume
        source: clickhouse_replica_data
        target: /var/lib/clickhouse
      - type: bind
        source: ./clickhouse-replica/users.d
        target: /etc/clickhouse-server/users.d
      - type: bind
        source: ./clickhouse-replica/config.d
        target: /etc/clickhouse-server/config.d
  minio:
    image: docker.io/bitnami/minio:2024.4.18
    hostname: minio
    environment:
      MINIO_ROOT_USER: "minio"
      MINIO_ROOT_PASSWORD: "miniosecret"
      MINIO_DISTRIBUTED_MODE_ENABLED: "no"
      MINIO_SKIP_CLIENT: "yes"
    restart: always
    ports:
      - "59000:9000"
      - "59001:9001"
    volumes:
      - type: volume
        source: minio_data
        target: /bitnami/minio/data
      - type: volume
        source: minio_certs
        target: /certs
  prometheus:
    image: docker.io/prom/prometheus:latest
    hostname: prometheus
    user: "0"
    cpus: 0.25
    restart: always
    ports:
      - "9090:9090"
    volumes:
      - type: bind
        source: ./prometheus/prometheus.yml
        target: /etc/prometheus/prometheus.yml
      - type: volume
        source: prometheus_data
        target: /prometheus
  nifi:
    image: docker.io/apache/nifi:2.4.0
    hostname: nifi
    environment:
      SINGLE_USER_CREDENTIALS_USERNAME: "admin"
      SINGLE_USER_CREDENTIALS_PASSWORD: "123456789012"
    ports:
      - "8443:8443"
      - "8081:8081"
    volumes:
      - type: volume
        source: nifi_state
        target: /opt/nifi/nifi-current/state
      - type: volume
        source: nifi_content_repository
        target: /opt/nifi/nifi-current/content_repository
      - type: volume
        source: nifi_flowfile_repository
        target: /opt/nifi/nifi-current/flowfile_repository
      - type: volume
        source: nifi_nar_extensions
        target: /opt/nifi/nifi-current/nar_extensions
      - type: volume
        source: nifi_python_extensions
        target: /opt/nifi/nifi-current/python_extensions
      - type: volume
        source: nifi_conf
        target: /opt/nifi/nifi-current/conf
      - type: volume
        source: nifi_provenance_repository
        target: /opt/nifi/nifi-current/provenance_repository
      - type: volume
        source: nifi_database_repository
        target: /opt/nifi/nifi-current/database_repository
      - type: volume
        source: nifi_logs
        target: /opt/nifi/nifi-current/logs
  kafka:
    image: docker.io/bitnami/kafka:3.7.0
    hostname: kafka
    environment:
      KAFKA_KRAFT_CLUSTER_ID: "49e43e60-dce9-4c9e-8f40-5e0a9f4ea255"
      KAFKA_CFG_NODE_ID: "1"
      KAFKA_CFG_PROCESS_ROLES: controller,broker
      KAFKA_CFG_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
      KAFKA_CFG_CONTROLLER_LISTENER_NAMES: CONTROLLER
    restart: always
    volumes:
      - type: volume
        source: kafka_data
        target: /bitnami
  akhq:
    image: docker.io/tchiotludo/akhq:0.26.0
    environment:
      AKHQ_CONFIGURATION: |
        akhq:
          connections:
            kafka:
              properties:
                bootstrap.servers: "kafka:9092"
    healthcheck:
      disable: true
    restart: always
    ports:
      - "8082:8080"
  superset:
    image: docker.io/apache/superset:latest
    environment:
      SUPERSET_SECRET_KEY: SA63+Nl8QFYt8qxBZVoOp/8X68PbnknMrAdBmrLg/fXgZqd8laOWVb2f
    restart: always
    ports:
      - 8088:8088
    volumes:
      - type: volume
        source: superset_data
        target: /app
  postgresql:
    image: docker.io/postgres:15
    command: >
      postgres 
      -c wal_level=logical
      -c max_replication_slots=10
    environment:
      POSTGRES_USER: "postgres"
      POSTGRES_PASSWORD: "postgres"
    restart: always
    ports:
      - "5432:5432"
    volumes:
      - type: volume
        source: postgresql_data
        target: /var/lib/postgresql/data

volumes:
  zookeeper_data:
  zookeeper_datalog:
  zookeeper_logs:
  clickhouse_data:
  clickhouse_replica_data:
  minio_data:
  minio_certs:
  prometheus_data:
  nifi_state:
  nifi_content_repository:
  nifi_flowfile_repository:
  nifi_nar_extensions:
  nifi_python_extensions:
  nifi_conf:
  nifi_provenance_repository:
  nifi_database_repository:
  nifi_logs:
  kafka_data:
  superset_data:
  postgresql_data:
